{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import  os \n",
    "from  random import shuffle\n",
    "from tqdm import tqdm\n",
    "tqdm.monitor_interval = 0\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_dir = r'E:\\skin cancer detection\\train'\n",
    "Test_dir = r'E:\\skin cancer detection\\test'\n",
    "IMG_SIZE = 50\n",
    "LR = 0.0003\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME ='mvb-{}-{}.model'.format(LR, '2conv-basic-video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img[0]\n",
    "    if word_label == 'm': return [1,0]\n",
    "    elif word_label == 'b': return [0,1]\n",
    "\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(Train_dir)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(Train_dir,img)\n",
    "        input_img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        if input_img is not None:\n",
    "            img = cv2.resize(input_img, (IMG_SIZE,IMG_SIZE))\n",
    "            training_data.append([np.array(img), np.array(label)])\n",
    "        else:\n",
    "            print(\"image not loaded\")\n",
    "\n",
    "\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n",
    "\n",
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(Test_dir)):\n",
    "        path = os.path.join(Test_dir, img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE),(IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▋                           | 967/3230 [00:12<00:29, 76.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image not loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 3230/3230 [01:39<00:00, 32.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From c:\\users\\hk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir ='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-50]\n",
    "test = train_data[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 999  | total loss: 0.24964 | time: 15.092s\n",
      "| Adam | epoch: 020 | loss: 0.24964 - acc: 0.8865 -- iter: 3136/3179\n",
      "Training Step: 1000  | total loss: 0.24768 | time: 16.395s\n",
      "| Adam | epoch: 020 | loss: 0.24768 - acc: 0.8916 | val_loss: 0.39539 - val_acc: 0.7800 -- iter: 3179/3179\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=20, validation_set=({'input': test_x}, {'targets': test_y}), snapshot_step=40, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:E:\\skin cancer detection\\mvb-0.0003-2conv-basic-video.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 134.67it/s]\n"
     ]
    },
    
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 50, 50) for Tensor 'input/X:0', which has shape '(?, 50, 50, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7b814324646b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     np.expand_dims(orig, axis=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mmodel_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morig\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_out\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'm'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m    256\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tflearn\\helpers\\evaluator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, feed_dict)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1105\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (1, 50, 50) for Tensor 'input/X:0', which has shape '(?, 50, 50, 3)'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAE8AAABICAYAAAC3Mag+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAAi5JREFUeJzt3DFrFGEUheH3GLFJbRUFLSQh7Yr+hVjZmlpI5Q/wj9hsEdIplna2NhZmu4gIwcbFQsReCVwrIWhgv+yZ3eTbnAdSbJgMNy+zbC7MRFVFzOfaRQ/Qs8QzJJ4h8QyJZ0g8w8x4kvYlfZd0tIyBetJy5R0AOwueo0sz41XVO+DnEmbpzvWhTiRpD9gDWF9fH21tbQ116qWaTCY/qupm08FVNfMLuAMctRxbVYxGo+oVcFiNv2c+bQ2JZ2j5U+Ul8B7YlDSV9HTxY/Vh5gdGVe0uY5Ae5W1rSDxD4hkSz5B4hsQzJJ4h8QyJZ0g8Q+IZEs+QeIbEMySeIfEMiWdIPEPiGRLPkHiGxDMkniHxDIlnSDxD4hkSz5B4hqZ4knYkfZZ0LOn5oofqRcv9eWvAC+ARsA3sStpe9GA9aLnyHgDHVfWlqn4Dr4DHix2rDy13w28AX0+9ngIP/z3o9N3wwK+OH3rZbD2wJZ7O+N5/TzhX1RgYA0g6rKr7rUNcJpIOW49tedtOgdunXt8Cvp13qFXUEu8DcE/SXUk3gCfAm8WO1YeWG7pPJD0D3gJrwH5VfZzxY+MhhrsgzbOr8g8a5pYNw5B4hkHj9bzGzfNQ9mDxVmCNO+CcD2UPeeV1vcbVHA9lDxnvrDVuY8DzXzpDxmta41bJkPGu3Bo3ZLwrt8YNFq+qToC/a9wn4HXDGndpzPNQdtYzQzYMQ+IZEs+QeIbEMySeIfEMfwBN1IdCqcgiIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x34573bd4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_data = process_test_data()\n",
    "fig = plt.figure()\n",
    "#test_data = np.load('test_data.npy')\n",
    "\n",
    "\n",
    "for num, data in enumerate(test_data[16:20]):\n",
    "    # malignant is 1:0, bengin is 0:1\n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(5,6, num + 1)\n",
    "    orig = img_data\n",
    "#     data = img_data.reshape(51, 51, 3)\n",
    "#     np.expand_dims(orig, axis=0)\n",
    "    \n",
    "    model_out = model.predict([orig])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 1: str_label='m'\n",
    "    else: str_label = 'b'\n",
    "        \n",
    "    y.imshow(orig, cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
